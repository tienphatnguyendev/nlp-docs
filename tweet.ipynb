{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data wrangling\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Reading the data \n",
    "d = pd.read_csv('Tweets.csv', header=None)\n",
    "\n",
    "# Adding the columns \n",
    "d.columns = ['INDEX', 'GAME', \"SENTIMENT\", 'TEXT']\n",
    "\n",
    "# Leaving only the positive and the negative sentiments \n",
    "d = d[d['SENTIMENT'].isin(['Positive', 'Negative'])]\n",
    "\n",
    "# Encoding the sentiments that the negative will be 1 and the positive 0\n",
    "d['SENTIMENT'] = d['SENTIMENT'].apply(lambda x: 0 if x == 'Positive' else 1)\n",
    "\n",
    "# Dropping missing values\n",
    "d = d.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_word_index(\n",
    "    x: str, \n",
    "    shift_for_padding: bool = False, \n",
    "    char_level = False): \n",
    "    \"\"\"\n",
    "    Function that scans a given text and creates two dictionaries:\n",
    "    - word2idx: dictionary mapping words to integers\n",
    "    - idx2word: dictionary mapping integers to words\n",
    "\n",
    "    Args:\n",
    "        x (str): text to scan\n",
    "        shift_for_padding (bool, optional): If True, the function will add 1 to all the indexes.\n",
    "            This is done to reserve the 0 index for padding. Defaults to False.\n",
    "        char_level (bool, optional): If True, the function will create a character level dictionary.\n",
    "        \n",
    "    Returns:\n",
    "        Tuple[dict, dict]: word2idx and idx2word dictionaries\n",
    "    \"\"\"\n",
    "    # Ensuring that the text is a string\n",
    "    if not isinstance(x, str):\n",
    "        try: \n",
    "            x = str(x)\n",
    "        except:\n",
    "            raise Exception('The text must be a string or a string convertible object')\n",
    "        \n",
    "    # Spliting the text into words\n",
    "    words = []\n",
    "    if char_level:\n",
    "        # The list() function of a string will return a list of characters\n",
    "        words = list(x)\n",
    "    else:\n",
    "        # Spliting the text into words by spaces\n",
    "        words = x.split(' ')\n",
    "\n",
    "    # Creating the word2idx dictionary \n",
    "    word2idx = {}\n",
    "    for word in words: \n",
    "        if word not in word2idx: \n",
    "            # The len(word2idx) will always ensure that the \n",
    "            # new index is 1 + the length of the dictionary so far\n",
    "            word2idx[word] = len(word2idx)\n",
    "\n",
    "    # Adding the <UNK> token to the dictionary; This token will be used \n",
    "    # on new texts that were not seen during training.\n",
    "    # It will have the last index. \n",
    "    word2idx['<UNK>'] = len(word2idx)\n",
    "\n",
    "    if shift_for_padding:\n",
    "        # Adding 1 to all the indexes; \n",
    "        # The 0 index will be reserved for padding\n",
    "        word2idx = {k: v + 1 for k, v in word2idx.items()}\n",
    "\n",
    "    # Reversing the above dictionary and creating the idx2word dictionary\n",
    "    idx2word = {idx: word for word, idx in word2idx.items()}\n",
    "\n",
    "    # Returns the dictionaries\n",
    "    return word2idx, idx2word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (34410, 4)\n",
      "Test shape: (8603, 4)\n",
      "The size of the vocabulary is: 274\n"
     ]
    }
   ],
   "source": [
    "# Spliting to train test \n",
    "train, test = train_test_split(d, test_size=0.2, random_state=42)\n",
    "\n",
    "# Reseting the indexes \n",
    "train.reset_index(drop=True, inplace=True)\n",
    "test.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(f'Train shape: {train.shape}')\n",
    "print(f'Test shape: {test.shape}')\n",
    "\n",
    "\n",
    "# Joining all the texts into one string\n",
    "text = ' '.join(train['TEXT'].values)\n",
    "\n",
    "# Creating the word2idx and idx2word dictionaries\n",
    "word2idx, idx2word = create_word_index(text, shift_for_padding=True, char_level=True)\n",
    "\n",
    "# Printing the size of the vocabulary\n",
    "print(f'The size of the vocabulary is: {len(word2idx)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'I': 1,\n",
       " ' ': 2,\n",
       " 'd': 3,\n",
       " 'o': 4,\n",
       " 'w': 5,\n",
       " 'n': 6,\n",
       " 'l': 7,\n",
       " 'a': 8,\n",
       " 'e': 9,\n",
       " 'G': 10,\n",
       " 'T': 11,\n",
       " 'A': 12,\n",
       " '5': 13,\n",
       " 'm': 14,\n",
       " 'y': 15,\n",
       " 'X': 16,\n",
       " 'b': 17,\n",
       " 'x': 18,\n",
       " 'O': 19,\n",
       " '.': 20,\n",
       " 'f': 21,\n",
       " 'r': 22,\n",
       " 'g': 23,\n",
       " 't': 24,\n",
       " 'h': 25,\n",
       " 'i': 26,\n",
       " 's': 27,\n",
       " 'F': 28,\n",
       " '3': 29,\n",
       " 'k': 30,\n",
       " '2': 31,\n",
       " 'u': 32,\n",
       " 'c': 33,\n",
       " 'v': 34,\n",
       " 'p': 35,\n",
       " 'j': 36,\n",
       " '/': 37,\n",
       " '?': 38,\n",
       " '=': 39,\n",
       " '-': 40,\n",
       " 'H': 41,\n",
       " 'U': 42,\n",
       " '0': 43,\n",
       " '‚Ä¶': 44,\n",
       " 'P': 45,\n",
       " 'L': 46,\n",
       " 'N': 47,\n",
       " 'M': 48,\n",
       " 'E': 49,\n",
       " ',': 50,\n",
       " '!': 51,\n",
       " 'R': 52,\n",
       " 'D': 53,\n",
       " 'S': 54,\n",
       " 'B': 55,\n",
       " '@': 56,\n",
       " '‚Äô': 57,\n",
       " '8': 58,\n",
       " '4': 59,\n",
       " 'J': 60,\n",
       " 'C': 61,\n",
       " '&': 62,\n",
       " '–Ø': 63,\n",
       " '—Å': 64,\n",
       " '–ú': 65,\n",
       " '–æ': 66,\n",
       " '—è': 67,\n",
       " '–∫': 68,\n",
       " '–º': 69,\n",
       " '–ø': 70,\n",
       " '–∞': 71,\n",
       " '–Ω': 72,\n",
       " '–∏': 73,\n",
       " 'Y': 74,\n",
       " '‚Äú': 75,\n",
       " '‚Äù': 76,\n",
       " 'z': 77,\n",
       " \"'\": 78,\n",
       " ':': 79,\n",
       " 'K': 80,\n",
       " 'V': 81,\n",
       " '1': 82,\n",
       " '9': 83,\n",
       " ')': 84,\n",
       " '6': 85,\n",
       " 'q': 86,\n",
       " '(': 87,\n",
       " 'Z': 88,\n",
       " '\"': 89,\n",
       " '_': 90,\n",
       " '7': 91,\n",
       " 'W': 92,\n",
       " '‚Äì': 93,\n",
       " 'ü•∫': 94,\n",
       " 'Q': 95,\n",
       " '<': 96,\n",
       " '>': 97,\n",
       " 'ü§£': 98,\n",
       " '+': 99,\n",
       " '[': 100,\n",
       " ']': 101,\n",
       " 'ü§Ø': 102,\n",
       " '*': 103,\n",
       " '$': 104,\n",
       " '|': 105,\n",
       " '\\xa0': 106,\n",
       " '\\\\': 107,\n",
       " 'ü§î': 108,\n",
       " 'ü§¶': 109,\n",
       " '\\u200d': 110,\n",
       " '¬¥': 111,\n",
       " '%': 112,\n",
       " ';': 113,\n",
       " '\\u2066': 114,\n",
       " '\\u2069': 115,\n",
       " '‚è¨': 116,\n",
       " '^': 117,\n",
       " 'ü§†': 118,\n",
       " 'ü•≥': 119,\n",
       " 'ü§ì': 120,\n",
       " '‚Äº': 121,\n",
       " 'ü§™': 122,\n",
       " 'ü•∞': 123,\n",
       " 'ü§∑': 124,\n",
       " '‚Ç¨': 125,\n",
       " '‚Äò': 126,\n",
       " '–ì': 127,\n",
       " '–î': 128,\n",
       " '–ï': 129,\n",
       " 'ü•ä': 130,\n",
       " 'ü§ó': 131,\n",
       " '¬ª': 132,\n",
       " 'ÔøΩ': 133,\n",
       " 'ü§´': 134,\n",
       " '‚Üí': 135,\n",
       " '‚Ä¢': 136,\n",
       " '~': 137,\n",
       " '‚É£': 138,\n",
       " 'ü•¥': 139,\n",
       " '‚Ä≤': 140,\n",
       " '¬£': 141,\n",
       " '¬∑': 142,\n",
       " '‚Äî': 143,\n",
       " 'üß°': 144,\n",
       " '¬´': 145,\n",
       " 'ü§¨': 146,\n",
       " 'ü§ü': 147,\n",
       " '√©': 148,\n",
       " 'ü§ë': 149,\n",
       " 'üßô': 150,\n",
       " '‚âß': 151,\n",
       " '‚àá': 152,\n",
       " '‚â¶': 153,\n",
       " 'ü§©': 154,\n",
       " '‚Ñ¢': 155,\n",
       " '–°': 156,\n",
       " '–±': 157,\n",
       " '—é': 158,\n",
       " '—É': 159,\n",
       " '–ü': 160,\n",
       " '–π': 161,\n",
       " '—Ç': 162,\n",
       " '–µ': 163,\n",
       " '–õ': 164,\n",
       " '–ª': 165,\n",
       " '–≤': 166,\n",
       " '—å': 167,\n",
       " '—Ñ': 168,\n",
       " '—ã': 169,\n",
       " '—Ä': 170,\n",
       " '¬Ω': 171,\n",
       " '¬∂': 172,\n",
       " 'ü§Æ': 173,\n",
       " '#': 174,\n",
       " 'ü§°': 175,\n",
       " '¬π': 176,\n",
       " '‚àí': 177,\n",
       " '‚Äû': 178,\n",
       " 'ü§®': 179,\n",
       " '„ÄÇ': 180,\n",
       " 'üßê': 181,\n",
       " '–û': 182,\n",
       " '–ë': 183,\n",
       " '–ò': 184,\n",
       " '–¢': 185,\n",
       " '–¨': 186,\n",
       " '–∂': 187,\n",
       " '–§': 188,\n",
       " '–†': 189,\n",
       " '–ê': 190,\n",
       " '–í': 191,\n",
       " '–ö': 192,\n",
       " '–¶': 193,\n",
       " '–ù': 194,\n",
       " '‚Äª': 195,\n",
       " 'üôÇ': 196,\n",
       " 'ü¶å': 197,\n",
       " 'ü§û': 198,\n",
       " '–ó': 199,\n",
       " 'ü•µ': 200,\n",
       " '¬Æ': 201,\n",
       " '‚Ñê': 202,\n",
       " '‚Ñì': 203,\n",
       " 'Ÿ•': 204,\n",
       " '‚àö': 205,\n",
       " 'œÖ': 206,\n",
       " '‚Ä†': 207,\n",
       " 'ü§§': 208,\n",
       " '‚è≥': 209,\n",
       " 'Àà': 210,\n",
       " ' å': 211,\n",
       " 'Œ∏': 212,\n",
       " '…ô': 213,\n",
       " ' ä': 214,\n",
       " 'üß¢': 215,\n",
       " '¬©': 216,\n",
       " 'ü•ò': 217,\n",
       " 'ü™ì': 218,\n",
       " '{': 219,\n",
       " 'ü§•': 220,\n",
       " '‚Äñ': 221,\n",
       " 'ü§ù': 222,\n",
       " '‚åö': 223,\n",
       " 'ü¶ä': 224,\n",
       " '\\u2063': 225,\n",
       " '‚Ä°': 226,\n",
       " 'üßª': 227,\n",
       " 'ü§≥': 228,\n",
       " '√ó': 229,\n",
       " 'ü•á': 230,\n",
       " 'ü¶Å': 231,\n",
       " '—á': 232,\n",
       " 'ü§ß': 233,\n",
       " '¬≤': 234,\n",
       " '–≥': 235,\n",
       " 'Ôºö': 236,\n",
       " 'ÿÆ': 237,\n",
       " 'ŸÑ': 238,\n",
       " 'ÿß': 239,\n",
       " 'ÿµ': 240,\n",
       " 'ÿπ': 241,\n",
       " 'ÿ®': 242,\n",
       " 'Ÿá': 243,\n",
       " '√Ø': 244,\n",
       " '¬±': 245,\n",
       " '¬°': 246,\n",
       " '√≠': 247,\n",
       " '√°': 248,\n",
       " '√≥': 249,\n",
       " '‚Ä≥': 250,\n",
       " '¬ß': 251,\n",
       " '–≠': 252,\n",
       " '„Éª': 253,\n",
       " 'ÿ≠': 254,\n",
       " 'Ÿä': 255,\n",
       " 'ÿ™': 256,\n",
       " 'ü•ñ': 257,\n",
       " 'ü•Ç': 258,\n",
       " 'ü§ï': 259,\n",
       " 'ü§ñ': 260,\n",
       " '`': 261,\n",
       " '\\u200b': 262,\n",
       " '‚ñ†': 263,\n",
       " '‚Üë': 264,\n",
       " '–ñ': 265,\n",
       " '–ô': 266,\n",
       " '¬≥': 267,\n",
       " 'œâ': 268,\n",
       " '–∑': 269,\n",
       " '‚Äö': 270,\n",
       " '—à': 271,\n",
       " '√ß': 272,\n",
       " 'ü§∏': 273,\n",
       " '<UNK>': 274}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>INDEX</th>\n",
       "      <th>GAME</th>\n",
       "      <th>SENTIMENT</th>\n",
       "      <th>TEXT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5166</td>\n",
       "      <td>GrandTheftAuto(GTA)</td>\n",
       "      <td>0</td>\n",
       "      <td>I downloaded GTA 5 on my new Xbox One. I forgo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2785</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>1</td>\n",
       "      <td>For more then 3 weeks now 2k uk hasnt drawn a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1585</td>\n",
       "      <td>Battlefield</td>\n",
       "      <td>0</td>\n",
       "      <td>. PLATINUM NAME.  .. running back through and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10484</td>\n",
       "      <td>RedDeadRedemption(RDR)</td>\n",
       "      <td>0</td>\n",
       "      <td>Red Dead or Redemption is just about Super Mar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3385</td>\n",
       "      <td>Facebook</td>\n",
       "      <td>0</td>\n",
       "      <td>Hey @Facebook this showed up on my feed recent...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   INDEX                    GAME  SENTIMENT  \\\n",
       "0   5166     GrandTheftAuto(GTA)          0   \n",
       "1   2785             Borderlands          1   \n",
       "2   1585             Battlefield          0   \n",
       "3  10484  RedDeadRedemption(RDR)          0   \n",
       "4   3385                Facebook          0   \n",
       "\n",
       "                                                TEXT  \n",
       "0  I downloaded GTA 5 on my new Xbox One. I forgo...  \n",
       "1  For more then 3 weeks now 2k uk hasnt drawn a ...  \n",
       "2  . PLATINUM NAME.  .. running back through and ...  \n",
       "3  Red Dead or Redemption is just about Super Mar...  \n",
       "4  Hey @Facebook this showed up on my feed recent...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    34410.000000\n",
       "mean       103.600262\n",
       "std         79.972798\n",
       "min          1.000000\n",
       "25%         41.000000\n",
       "50%         83.000000\n",
       "75%        148.000000\n",
       "max        727.000000\n",
       "Name: seq_len, dtype: float64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For each row in the train and test set, we will create a list of integers\n",
    "# that will represent the words in the text\n",
    "train['text_int'] = train['TEXT'].apply(lambda x: [word2idx.get(word, word2idx['<UNK>']) for word in list(x)])\n",
    "test['text_int'] = test['TEXT'].apply(lambda x: [word2idx.get(word, word2idx['<UNK>']) for word in list(x)])\n",
    "\n",
    "# Calculating the length of sequences in the train set \n",
    "train['seq_len'] = train['text_int'].apply(lambda x: len(x))\n",
    "\n",
    "# Describing the length of the sequences\n",
    "train['seq_len'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I downloaded GTA 5 on my new Xbox One. I forgot the old it is lol.'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join(idx2word.get(character) for character in train['text_int'][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>INDEX</th>\n",
       "      <th>GAME</th>\n",
       "      <th>SENTIMENT</th>\n",
       "      <th>TEXT</th>\n",
       "      <th>text_int</th>\n",
       "      <th>seq_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5166</td>\n",
       "      <td>GrandTheftAuto(GTA)</td>\n",
       "      <td>0</td>\n",
       "      <td>I downloaded GTA 5 on my new Xbox One. I forgo...</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 4, 8, 3, 9, 3, 2, 10, 11...</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2785</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>1</td>\n",
       "      <td>For more then 3 weeks now 2k uk hasnt drawn a ...</td>\n",
       "      <td>[28, 4, 22, 2, 14, 4, 22, 9, 2, 24, 25, 9, 6, ...</td>\n",
       "      <td>230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1585</td>\n",
       "      <td>Battlefield</td>\n",
       "      <td>0</td>\n",
       "      <td>. PLATINUM NAME.  .. running back through and ...</td>\n",
       "      <td>[20, 2, 45, 46, 12, 11, 1, 47, 42, 48, 2, 47, ...</td>\n",
       "      <td>205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10484</td>\n",
       "      <td>RedDeadRedemption(RDR)</td>\n",
       "      <td>0</td>\n",
       "      <td>Red Dead or Redemption is just about Super Mar...</td>\n",
       "      <td>[52, 9, 3, 2, 53, 9, 8, 3, 2, 4, 22, 2, 52, 9,...</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3385</td>\n",
       "      <td>Facebook</td>\n",
       "      <td>0</td>\n",
       "      <td>Hey @Facebook this showed up on my feed recent...</td>\n",
       "      <td>[41, 9, 15, 2, 56, 28, 8, 33, 9, 17, 4, 4, 30,...</td>\n",
       "      <td>268</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   INDEX                    GAME  SENTIMENT  \\\n",
       "0   5166     GrandTheftAuto(GTA)          0   \n",
       "1   2785             Borderlands          1   \n",
       "2   1585             Battlefield          0   \n",
       "3  10484  RedDeadRedemption(RDR)          0   \n",
       "4   3385                Facebook          0   \n",
       "\n",
       "                                                TEXT  \\\n",
       "0  I downloaded GTA 5 on my new Xbox One. I forgo...   \n",
       "1  For more then 3 weeks now 2k uk hasnt drawn a ...   \n",
       "2  . PLATINUM NAME.  .. running back through and ...   \n",
       "3  Red Dead or Redemption is just about Super Mar...   \n",
       "4  Hey @Facebook this showed up on my feed recent...   \n",
       "\n",
       "                                            text_int  seq_len  \n",
       "0  [1, 2, 3, 4, 5, 6, 7, 4, 8, 3, 9, 3, 2, 10, 11...       66  \n",
       "1  [28, 4, 22, 2, 14, 4, 22, 9, 2, 24, 25, 9, 6, ...      230  \n",
       "2  [20, 2, 45, 46, 12, 11, 1, 47, 42, 48, 2, 47, ...      205  \n",
       "3  [52, 9, 3, 2, 53, 9, 8, 3, 2, 4, 22, 2, 52, 9,...       62  \n",
       "4  [41, 9, 15, 2, 56, 28, 8, 33, 9, 17, 4, 4, 30,...      268  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop('text_int_size', inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['INDEX', 'GAME', 'SENTIMENT', 'TEXT', 'text_int', 'seq_len'], dtype='object')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_sequences(x: list, pad_length: int) -> list:\n",
    "    \"\"\"\n",
    "    Function that pads a given list of integers to a given length\n",
    "\n",
    "    Args:\n",
    "        x (list): list of integers to pad\n",
    "        pad_length (int): length to pad\n",
    "\n",
    "    Returns:\n",
    "        list: padded list of integers\n",
    "    \"\"\"\n",
    "    # Getting the length of the list\n",
    "    len_x = len(x)\n",
    "\n",
    "    # Checking if the length of the list is less than the pad_length\n",
    "    if len_x < pad_length: \n",
    "        # Padding the list with 0s\n",
    "        x = x + [0] * (pad_length - len_x)\n",
    "    else: \n",
    "        # Truncating the list to the desired length\n",
    "        x = x[:pad_length]\n",
    "\n",
    "    # Returning the padded list\n",
    "    return x\n",
    "\n",
    "# Padding the train and test sequences \n",
    "train['text_int'] = train['text_int'].apply(lambda x: pad_sequences(x, 200))\n",
    "test['text_int'] = test['text_int'].apply(lambda x: pad_sequences(x, 200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentClassifier(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Class that defines the sentiment classifier model\n",
    "    \"\"\"\n",
    "    def __init__(self, vocab_size, embedding_dim):\n",
    "        super(SentimentClassifier, self).__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding(vocab_size + 1, embedding_dim)\n",
    "        self.lstm = nn.LSTM(input_size=embedding_dim, hidden_size=1, batch_first=True)\n",
    "        self.fc = nn.Linear(1, 1)  # Output with a single neuron for binary classification\n",
    "        self.sigmoid = nn.Sigmoid()  # Sigmoid activation\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)  # Embedding layer\n",
    "        output, _ = self.lstm(x)  # RNN layer\n",
    "\n",
    "        # Use the short term memory from the last time step as the representation of the sequence\n",
    "        x = output[:, -1, :]\n",
    "\n",
    "        # Fully connected layer with a single neuron\n",
    "        x = self.fc(x) \n",
    "        \n",
    "        # Converting to probabilities\n",
    "        x = self.sigmoid(x)\n",
    "\n",
    "        # Flattening the output\n",
    "        x = x.squeeze()\n",
    "        \n",
    "        return x\n",
    "\n",
    "# Initiating the model \n",
    "model = SentimentClassifier(vocab_size=len(word2idx), embedding_dim=16)\n",
    "\n",
    "# Initiating the criterion and the optimizer\n",
    "criterion = nn.BCELoss() # Binary cross entropy loss\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class TextClassificationDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # The x is named as text_int and the y as airline_sentiment\n",
    "        x = self.data.iloc[idx]['text_int']\n",
    "        y = self.data.iloc[idx]['SENTIMENT']\n",
    "        \n",
    "        # Converting the x and y to torch tensors\n",
    "        x = torch.tensor(x)\n",
    "        y = torch.tensor(y)\n",
    "\n",
    "        # Converting the y variable to float \n",
    "        y = y.float()\n",
    "\n",
    "        # Returning the x and y\n",
    "        return x, y\n",
    "    \n",
    "# Creating the train and test loaders\n",
    "train_loader = DataLoader(TextClassificationDataset(train), batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(TextClassificationDataset(test), batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 0.6926363456204921\n",
      "Epoch: 20, Loss: 0.6528273011007274\n",
      "Epoch: 40, Loss: 0.6473784191623939\n",
      "Epoch: 60, Loss: 0.6437770354260299\n",
      "Epoch: 80, Loss: 0.6422728939625854\n"
     ]
    }
   ],
   "source": [
    "# Defining the number of epochs\n",
    "epochs = 100\n",
    "\n",
    "# Setting the model to train mode\n",
    "model.train()\n",
    "\n",
    "# Saving of the loss values\n",
    "losses = []\n",
    "\n",
    "# Iterating through epochs\n",
    "for epoch in range(epochs):\n",
    "    # Initiating the total loss \n",
    "    total_loss = 0\n",
    "\n",
    "    for batch_idx, (inputs, labels) in enumerate(train_loader):\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()  # Zero the gradients\n",
    "        outputs = model(inputs)  # Forward pass\n",
    "\n",
    "        loss = criterion(outputs, labels)  # Compute the loss\n",
    "        loss.backward()  # Backpropagation\n",
    "        optimizer.step()  # Update the model's parameters\n",
    "\n",
    "        # Adding the loss to the total loss\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    # Calculating the average loss\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "\n",
    "    # Appending the loss to the list containing the losses\n",
    "    losses.append(avg_loss)\n",
    "\n",
    "    # Printing the loss every n epochs\n",
    "    if epoch % 20 == 0:\n",
    "        print(f'Epoch: {epoch}, Loss: {avg_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".scfnn-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
